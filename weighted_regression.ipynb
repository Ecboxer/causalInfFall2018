{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.api import WLS, OLS\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000\n",
    "a = np.random.uniform(0.1, 1., size=N)\n",
    "b = np.random.uniform(0.1, 1., size=N)\n",
    "\n",
    "v0 = np.random.normal(0., 1., size=N)\n",
    "v1 = np.random.normal(0., 1., size=N)\n",
    "\n",
    "p_d = 1. / (1. + np.exp(-(a + b)))\n",
    "d = np.random.binomial(1., p=p_d)\n",
    "\n",
    "y0 = 100 + 3*a + 2*b + v0\n",
    "y1 = 102 + 6*a + 4*b + v1\n",
    "y = (d==1)*y1 + (d==0)*y0\n",
    "\n",
    "X = pd.DataFrame({'$D$': d, '$A$': a, '$B$': b, '$Y$': y })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$A$</th>\n",
       "      <th>$B$</th>\n",
       "      <th>$D$</th>\n",
       "      <th>$Y$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.804654</td>\n",
       "      <td>0.244026</td>\n",
       "      <td>1</td>\n",
       "      <td>107.028005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.847228</td>\n",
       "      <td>0</td>\n",
       "      <td>101.537851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537685</td>\n",
       "      <td>0.836464</td>\n",
       "      <td>1</td>\n",
       "      <td>110.016315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.639418</td>\n",
       "      <td>0.305663</td>\n",
       "      <td>1</td>\n",
       "      <td>106.466189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275248</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>1</td>\n",
       "      <td>104.492944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        $A$       $B$  $D$         $Y$\n",
       "0  0.804654  0.244026    1  107.028005\n",
       "1  0.485549  0.847228    0  101.537851\n",
       "2  0.537685  0.836464    1  110.016315\n",
       "3  0.639418  0.305663    1  106.466189\n",
       "4  0.275248  0.165690    1  104.492944"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1812111079441365"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['$D$'] == 1].mean()['$Y$'] - X[X['$D$'] == 0].mean()['$Y$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.734849005742652"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1 - y0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$D$\n",
       "0    102.490610\n",
       "1    102.826533\n",
       "Name: $Y_0$, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline bias?\n",
    "X = pd.DataFrame({'$D$': d, '$A$': a, '$B$': b, '$Y$': y, '$Y_0$': y0, '$Y_1$': y1 })\n",
    "X.groupby('$D$').mean()['$Y_0$']\n",
    "# looks like it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$D$\n",
       "0    4.527131\n",
       "1    4.838852\n",
       "Name: $\\delta$, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# differential treatment effect bias?\n",
    "X['$\\delta$'] = X['$Y_1$'] - X['$Y_0$'] \n",
    "X.groupby('$D$').mean()['$\\delta$']\n",
    "# looks like it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Identify a set Z satisfying the back door criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data generating process, $D$ and $Y$ are both caused by $A$ and $B$. We need to control for both $A$ and $B$ to satisfy the back door criterion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Compute propensity scores, $P(D=1|Z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propensity_model = LogisticRegression(C=1e12) # we don't want bias due to regularization!! use a large C.\n",
    "propensity_model = propensity_model.fit(X[['$A$', '$B$']], X['$D$'])\n",
    "X['$P(D=1|A,B)$'] = propensity_model.predict_proba(X[['$A$', '$B$']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$A$</th>\n",
       "      <th>$B$</th>\n",
       "      <th>$D$</th>\n",
       "      <th>$Y$</th>\n",
       "      <th>$Y_0$</th>\n",
       "      <th>$Y_1$</th>\n",
       "      <th>$\\delta$</th>\n",
       "      <th>$P(D=1|A,B)$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.804654</td>\n",
       "      <td>0.244026</td>\n",
       "      <td>1</td>\n",
       "      <td>107.028005</td>\n",
       "      <td>101.818088</td>\n",
       "      <td>107.028005</td>\n",
       "      <td>5.209917</td>\n",
       "      <td>0.751613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.847228</td>\n",
       "      <td>0</td>\n",
       "      <td>101.537851</td>\n",
       "      <td>101.537851</td>\n",
       "      <td>109.304363</td>\n",
       "      <td>7.766511</td>\n",
       "      <td>0.789054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537685</td>\n",
       "      <td>0.836464</td>\n",
       "      <td>1</td>\n",
       "      <td>110.016315</td>\n",
       "      <td>103.192129</td>\n",
       "      <td>110.016315</td>\n",
       "      <td>6.824186</td>\n",
       "      <td>0.796248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.639418</td>\n",
       "      <td>0.305663</td>\n",
       "      <td>1</td>\n",
       "      <td>106.466189</td>\n",
       "      <td>101.839289</td>\n",
       "      <td>106.466189</td>\n",
       "      <td>4.626899</td>\n",
       "      <td>0.729696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275248</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>1</td>\n",
       "      <td>104.492944</td>\n",
       "      <td>102.577566</td>\n",
       "      <td>104.492944</td>\n",
       "      <td>1.915378</td>\n",
       "      <td>0.621314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        $A$       $B$  $D$         $Y$       $Y_0$       $Y_1$  $\\delta$  \\\n",
       "0  0.804654  0.244026    1  107.028005  101.818088  107.028005  5.209917   \n",
       "1  0.485549  0.847228    0  101.537851  101.537851  109.304363  7.766511   \n",
       "2  0.537685  0.836464    1  110.016315  103.192129  110.016315  6.824186   \n",
       "3  0.639418  0.305663    1  106.466189  101.839289  106.466189  4.626899   \n",
       "4  0.275248  0.165690    1  104.492944  102.577566  104.492944  1.915378   \n",
       "\n",
       "   $P(D=1|A,B)$  \n",
       "0      0.751613  \n",
       "1      0.789054  \n",
       "2      0.796248  \n",
       "3      0.729696  \n",
       "4      0.621314  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Compute weights, $w_{i, ATE} = \\frac{1}{p_i}$ if $d=1$, and  $w_{i, ATE} = \\frac{1}{1 - p_i}$ if $d=0$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['$W_{ATE}$'] = (X['$D$'] == 1)* 1. / X['$P(D=1|A,B)$'] + (X['$D$'] == 0)* 1. /(1. - X['$P(D=1|A,B)$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$A$</th>\n",
       "      <th>$B$</th>\n",
       "      <th>$D$</th>\n",
       "      <th>$Y$</th>\n",
       "      <th>$Y_0$</th>\n",
       "      <th>$Y_1$</th>\n",
       "      <th>$\\delta$</th>\n",
       "      <th>$P(D=1|A,B)$</th>\n",
       "      <th>$W_{ATE}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.804654</td>\n",
       "      <td>0.244026</td>\n",
       "      <td>1</td>\n",
       "      <td>107.028005</td>\n",
       "      <td>101.818088</td>\n",
       "      <td>107.028005</td>\n",
       "      <td>5.209917</td>\n",
       "      <td>0.751613</td>\n",
       "      <td>1.330472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.847228</td>\n",
       "      <td>0</td>\n",
       "      <td>101.537851</td>\n",
       "      <td>101.537851</td>\n",
       "      <td>109.304363</td>\n",
       "      <td>7.766511</td>\n",
       "      <td>0.789054</td>\n",
       "      <td>4.740547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537685</td>\n",
       "      <td>0.836464</td>\n",
       "      <td>1</td>\n",
       "      <td>110.016315</td>\n",
       "      <td>103.192129</td>\n",
       "      <td>110.016315</td>\n",
       "      <td>6.824186</td>\n",
       "      <td>0.796248</td>\n",
       "      <td>1.255890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.639418</td>\n",
       "      <td>0.305663</td>\n",
       "      <td>1</td>\n",
       "      <td>106.466189</td>\n",
       "      <td>101.839289</td>\n",
       "      <td>106.466189</td>\n",
       "      <td>4.626899</td>\n",
       "      <td>0.729696</td>\n",
       "      <td>1.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275248</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>1</td>\n",
       "      <td>104.492944</td>\n",
       "      <td>102.577566</td>\n",
       "      <td>104.492944</td>\n",
       "      <td>1.915378</td>\n",
       "      <td>0.621314</td>\n",
       "      <td>1.609492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        $A$       $B$  $D$         $Y$       $Y_0$       $Y_1$  $\\delta$  \\\n",
       "0  0.804654  0.244026    1  107.028005  101.818088  107.028005  5.209917   \n",
       "1  0.485549  0.847228    0  101.537851  101.537851  109.304363  7.766511   \n",
       "2  0.537685  0.836464    1  110.016315  103.192129  110.016315  6.824186   \n",
       "3  0.639418  0.305663    1  106.466189  101.839289  106.466189  4.626899   \n",
       "4  0.275248  0.165690    1  104.492944  102.577566  104.492944  1.915378   \n",
       "\n",
       "   $P(D=1|A,B)$  $W_{ATE}$  \n",
       "0      0.751613   1.330472  \n",
       "1      0.789054   4.740547  \n",
       "2      0.796248   1.255890  \n",
       "3      0.729696   1.370434  \n",
       "4      0.621314   1.609492  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Compute the weighted regression estimate for the causal effect, with the specification $Y \\sim \\delta D + \\alpha + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>$Y$</td>       <th>  R-squared:         </th> <td>   0.642</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.642</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.584e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Feb 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:32:55</td>     <th>  Log-Likelihood:    </th> <td> -20675.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>4.135e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9998</td>      <th>  BIC:               </th> <td>4.137e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$D$</th>       <td>    4.7723</td> <td>    0.038</td> <td>  125.868</td> <td> 0.000</td> <td>    4.698</td> <td>    4.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  102.7331</td> <td>    0.029</td> <td> 3578.570</td> <td> 0.000</td> <td>  102.677</td> <td>  102.789</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>22.284</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  18.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.025</td> <th>  Prob(JB):          </th> <td>0.000104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.796</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    $Y$   R-squared:                       0.642\n",
       "Model:                            WLS   Adj. R-squared:                  0.642\n",
       "Method:                 Least Squares   F-statistic:                 1.584e+04\n",
       "Date:                Thu, 15 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        19:32:55   Log-Likelihood:                -20675.\n",
       "No. Observations:               10000   AIC:                         4.135e+04\n",
       "Df Residuals:                    9998   BIC:                         4.137e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "$D$            4.7723      0.038    125.868      0.000       4.698       4.847\n",
       "intercept    102.7331      0.029   3578.570      0.000     102.677     102.789\n",
       "==============================================================================\n",
       "Omnibus:                       22.284   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.350\n",
       "Skew:                           0.025   Prob(JB):                     0.000104\n",
       "Kurtosis:                       2.796   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['intercept'] = 1.\n",
    "model = WLS(X['$Y$'], X[['$D$', 'intercept']], weights=X['$W_{ATE}$'])\n",
    "result = model.fit(cov_type='HC3') # use heteroskedasticity-consistent error bars\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with an OLS regression that controls for $A$ and $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>$Y$</td>       <th>  R-squared:         </th> <td>   0.869</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.869</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.206e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Feb 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:33:45</td>     <th>  Log-Likelihood:    </th> <td> -14923.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>2.985e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9996</td>      <th>  BIC:               </th> <td>2.988e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$D$</th>       <td>    4.6155</td> <td>    0.025</td> <td>  183.985</td> <td> 0.000</td> <td>    4.566</td> <td>    4.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$A$</th>       <td>    5.2805</td> <td>    0.042</td> <td>  126.972</td> <td> 0.000</td> <td>    5.199</td> <td>    5.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$B$</th>       <td>    3.4478</td> <td>    0.042</td> <td>   82.881</td> <td> 0.000</td> <td>    3.366</td> <td>    3.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   98.1063</td> <td>    0.037</td> <td> 2668.868</td> <td> 0.000</td> <td>   98.034</td> <td>   98.178</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.636</td> <th>  Durbin-Watson:     </th> <td>   2.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.441</td> <th>  Jarque-Bera (JB):  </th> <td>   1.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.009</td> <th>  Prob(JB):          </th> <td>   0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.060</td> <th>  Cond. No.          </th> <td>    7.41</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    $Y$   R-squared:                       0.869\n",
       "Model:                            OLS   Adj. R-squared:                  0.869\n",
       "Method:                 Least Squares   F-statistic:                 2.206e+04\n",
       "Date:                Thu, 15 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        19:33:45   Log-Likelihood:                -14923.\n",
       "No. Observations:               10000   AIC:                         2.985e+04\n",
       "Df Residuals:                    9996   BIC:                         2.988e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "$D$            4.6155      0.025    183.985      0.000       4.566       4.665\n",
       "$A$            5.2805      0.042    126.972      0.000       5.199       5.362\n",
       "$B$            3.4478      0.042     82.881      0.000       3.366       3.529\n",
       "intercept     98.1063      0.037   2668.868      0.000      98.034      98.178\n",
       "==============================================================================\n",
       "Omnibus:                        1.636   Durbin-Watson:                   2.009\n",
       "Prob(Omnibus):                  0.441   Jarque-Bera (JB):                1.630\n",
       "Skew:                          -0.009   Prob(JB):                        0.443\n",
       "Kurtosis:                       3.060   Cond. No.                         7.41\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['intercept'] = 1.\n",
    "model = OLS(X['$Y$'], X[['$D$', '$A$', '$B$', 'intercept']])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks good! the interval for the $D$ coefficient contains the value estimated above for `(y1 - y0).mean()`. What happens if the propensity model was mis-specified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000000\n",
    "a = np.random.uniform(0.1, 1., size=N)\n",
    "b = np.random.uniform(0.1, 1., size=N)\n",
    "\n",
    "v0 = np.random.normal(0., 1., size=N)\n",
    "v1 = np.random.normal(0., 1., size=N)\n",
    "\n",
    "p_d = 1. / (1. + np.exp(-(a + b + a*b)))  # now, the propensity model has the extra non-linearity from a*b!\n",
    "d = np.random.binomial(1., p=p_d)\n",
    "\n",
    "y1 = 102 + 3*a + 2*b + 6*a*b + v1\n",
    "y0 = 100 + 2*a + 1*b - 2*a*b + v0\n",
    "y = (d==1)*y1 + (d==0)*y0\n",
    "\n",
    "X = pd.DataFrame({'$D$': d, '$A$': a, '$B$': b, '$Y$': y })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.813625741696569"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['$D$'] == 1].mean()['$Y$'] - X[X['$D$'] == 0].mean()['$Y$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.521747543159587"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1 - y0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propensity_model = LogisticRegression(C=1e10) # we don't want bias due to regularization!! use a large C.\n",
    "propensity_model = propensity_model.fit(X[['$A$', '$B$']], X['$D$'])\n",
    "X['$P(D=1|A,B)$'] = propensity_model.predict_proba(X[['$A$', '$B$']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['$W_{ATE}$'] = (X['$D$'] == 1)* 1. / X['$P(D=1|A,B)$'] + (X['$D$'] == 0)* 1. /(1. - X['$P(D=1|A,B)$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>$Y$</td>       <th>  R-squared:         </th>  <td>   0.689</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.689</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.212e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Feb 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:36:27</td>     <th>  Log-Likelihood:    </th> <td>-2.1349e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1000000</td>     <th>  AIC:               </th>  <td>4.270e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>999998</td>      <th>  BIC:               </th>  <td>4.270e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$D$</th>       <td>    5.5168</td> <td>    0.004</td> <td> 1487.271</td> <td> 0.000</td> <td>    5.510</td> <td>    5.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  101.0504</td> <td>    0.003</td> <td> 3.85e+04</td> <td> 0.000</td> <td>  101.045</td> <td>  101.056</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>6407.987</td> <th>  Durbin-Watson:     </th> <td>   1.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5836.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.148</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.772</td>  <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    $Y$   R-squared:                       0.689\n",
       "Model:                            WLS   Adj. R-squared:                  0.689\n",
       "Method:                 Least Squares   F-statistic:                 2.212e+06\n",
       "Date:                Thu, 15 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        19:36:27   Log-Likelihood:            -2.1349e+06\n",
       "No. Observations:             1000000   AIC:                         4.270e+06\n",
       "Df Residuals:                  999998   BIC:                         4.270e+06\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "$D$            5.5168      0.004   1487.271      0.000       5.510       5.524\n",
       "intercept    101.0504      0.003   3.85e+04      0.000     101.045     101.056\n",
       "==============================================================================\n",
       "Omnibus:                     6407.987   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5836.864\n",
       "Skew:                           0.148   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.772   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['intercept'] = 1.\n",
    "model = WLS(X['$Y$'], X[['$D$', 'intercept']], weights=X['$W_{ATE}$'])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not bad! We're tolerant to a little mis-specification. That's probably partly a product of our specific data generating process. \n",
    "\n",
    "## Now let's try estimating the ATC and ATT\n",
    "\n",
    "Remember, $w_{i ,ATC} = \\frac{1-p_i}{p_i}$ if $d_i = 1$ and one if $d_i=0$. Also, $w_{i ,ATT} = \\frac{p_i}{1-p_i}$ if $d_i = 0$ and one if $d_i=1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['$W_{ATC}$'] = (X['$D$'] == 1)* (1. - X['$P(D=1|A,B)$']) / X['$P(D=1|A,B)$']  + (X['$D$'] == 0)* 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['$W_{ATT}$'] = (X['$D$'] == 1)* 1. + (X['$D$'] == 0)* X['$P(D=1|A,B)$'] /(1. - X['$P(D=1|A,B)$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>$Y$</td>       <th>  R-squared:         </th>  <td>   0.704</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.704</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.378e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Feb 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:51:30</td>     <th>  Log-Likelihood:    </th> <td>-2.1396e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1000000</td>     <th>  AIC:               </th>  <td>4.279e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>999998</td>      <th>  BIC:               </th>  <td>4.279e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$D$</th>       <td>    5.7311</td> <td>    0.004</td> <td> 1542.173</td> <td> 0.000</td> <td>    5.724</td> <td>    5.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  101.0681</td> <td>    0.003</td> <td> 3.84e+04</td> <td> 0.000</td> <td>  101.063</td> <td>  101.073</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18378.649</td> <th>  Durbin-Watson:     </th> <td>   1.997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>19005.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.327</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.828</td>   <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    $Y$   R-squared:                       0.704\n",
       "Model:                            WLS   Adj. R-squared:                  0.704\n",
       "Method:                 Least Squares   F-statistic:                 2.378e+06\n",
       "Date:                Thu, 15 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        19:51:30   Log-Likelihood:            -2.1396e+06\n",
       "No. Observations:             1000000   AIC:                         4.279e+06\n",
       "Df Residuals:                  999998   BIC:                         4.279e+06\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "$D$            5.7311      0.004   1542.173      0.000       5.724       5.738\n",
       "intercept    101.0681      0.003   3.84e+04      0.000     101.063     101.073\n",
       "==============================================================================\n",
       "Omnibus:                    18378.649   Durbin-Watson:                   1.997\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            19005.140\n",
       "Skew:                           0.327   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.828   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WLS(X['$Y$'], X[['$D$','intercept']], weights=X['$W_{ATT}$'])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>$Y$</td>       <th>  R-squared:         </th>  <td>   0.657</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.657</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.913e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Feb 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:50:20</td>     <th>  Log-Likelihood:    </th> <td>-2.1001e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1000000</td>     <th>  AIC:               </th>  <td>4.200e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>999998</td>      <th>  BIC:               </th>  <td>4.200e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$D$</th>       <td>    4.7256</td> <td>    0.003</td> <td> 1383.086</td> <td> 0.000</td> <td>    4.719</td> <td>    4.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  100.9807</td> <td>    0.002</td> <td> 4.18e+04</td> <td> 0.000</td> <td>  100.976</td> <td>  100.985</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>52307.546</td> <th>  Durbin-Watson:     </th> <td>   1.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>60870.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.593</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.231</td>   <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    $Y$   R-squared:                       0.657\n",
       "Model:                            WLS   Adj. R-squared:                  0.657\n",
       "Method:                 Least Squares   F-statistic:                 1.913e+06\n",
       "Date:                Thu, 15 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        14:50:20   Log-Likelihood:            -2.1001e+06\n",
       "No. Observations:             1000000   AIC:                         4.200e+06\n",
       "Df Residuals:                  999998   BIC:                         4.200e+06\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "$D$            4.7256      0.003   1383.086      0.000       4.719       4.732\n",
       "intercept    100.9807      0.002   4.18e+04      0.000     100.976     100.985\n",
       "==============================================================================\n",
       "Omnibus:                    52307.546   Durbin-Watson:                   1.930\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            60870.268\n",
       "Skew:                          -0.593   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.231   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WLS(X['$Y$'], X[['$D$','intercept']], weights=X['$W_{ATC}$'])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the true values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['$Y_1$'] = y1\n",
    "X['$Y_0$'] = y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.739338141875647"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated = X[X['$D$'] == 1]\n",
    "ATT = (treated['$Y_1$'] - treated['$Y_0$']).mean()\n",
    "ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.714818294637095"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control = X[X['$D$'] == 0]\n",
    "ATC = (control['$Y_1$'] - control['$Y_0$']).mean()\n",
    "ATC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So it looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000000\n",
    "a = np.random.uniform(0.1, 1., size=N)\n",
    "b = np.random.uniform(0.1, 1., size=N)\n",
    "\n",
    "v0 = np.random.normal(0., 1., size=N)\n",
    "v1 = np.random.normal(0., 1., size=N)\n",
    "\n",
    "p_d = 1. / (1. + np.exp(-(a + b + a*b)))  # now, the propensity model has the extra non-linearity from a*b!\n",
    "d = np.random.binomial(1., p=p_d)\n",
    "\n",
    "y1 = 102 + 3*a + 2*b + 6*a*b + v1\n",
    "y0 = 100 + 2*a + 1*b - 2*a*b + v0\n",
    "y = (d==1)*y1 + (d==0)*y0\n",
    "\n",
    "X = pd.DataFrame({'$D$': d, '$A$': a, '$B$': b, '$Y$': y })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.492944413986289"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1 - y0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.816296771833464"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['$D$'] == 1].mean()['$Y$'] - X[X['$D$'] == 0].mean()['$Y$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propensity_model = LogisticRegression(C=1e15) # we don't want bias due to regularization!! use a large C.\n",
    "propensity_model = propensity_model.fit(X[['$A$', '$B$']], X['$D$'])\n",
    "X['$P(D=1|A,B)$'] = propensity_model.predict_proba(X[['$A$', '$B$']])[:,1]\n",
    "\n",
    "X['$W_{ATE}$'] = (X['$D$'] == 1)* 1. / X['$P(D=1|A,B)$'] + (X['$D$'] == 0)* 1. /(1. - X['$P(D=1|A,B)$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>$Y$</td>       <th>  R-squared:         </th> <td>   0.816</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.816</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7390.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Feb 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:55:46</td>     <th>  Log-Likelihood:    </th> <td> -18758.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>3.753e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9993</td>      <th>  BIC:               </th> <td>3.758e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$D$</th>       <td>    5.4907</td> <td>    0.029</td> <td>  191.896</td> <td> 0.000</td> <td>    5.435</td> <td>    5.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$A^2$</th>     <td>    0.2355</td> <td>    0.239</td> <td>    0.987</td> <td> 0.324</td> <td>   -0.232</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$B^2$</th>     <td>   -0.0393</td> <td>    0.235</td> <td>   -0.167</td> <td> 0.867</td> <td>   -0.500</td> <td>    0.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$A$</th>       <td>    2.3316</td> <td>    0.293</td> <td>    7.956</td> <td> 0.000</td> <td>    1.757</td> <td>    2.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$B$</th>       <td>    1.6422</td> <td>    0.289</td> <td>    5.684</td> <td> 0.000</td> <td>    1.076</td> <td>    2.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$AB$</th>      <td>    2.0262</td> <td>    0.211</td> <td>    9.609</td> <td> 0.000</td> <td>    1.613</td> <td>    2.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   98.1921</td> <td>    0.112</td> <td>  873.772</td> <td> 0.000</td> <td>   97.972</td> <td>   98.412</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1708.714</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8378.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.745</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 7.229</td>  <th>  Cond. No.          </th> <td>    43.2</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    $Y$   R-squared:                       0.816\n",
       "Model:                            WLS   Adj. R-squared:                  0.816\n",
       "Method:                 Least Squares   F-statistic:                     7390.\n",
       "Date:                Thu, 15 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        19:55:46   Log-Likelihood:                -18758.\n",
       "No. Observations:               10000   AIC:                         3.753e+04\n",
       "Df Residuals:                    9993   BIC:                         3.758e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "$D$            5.4907      0.029    191.896      0.000       5.435       5.547\n",
       "$A^2$          0.2355      0.239      0.987      0.324      -0.232       0.703\n",
       "$B^2$         -0.0393      0.235     -0.167      0.867      -0.500       0.421\n",
       "$A$            2.3316      0.293      7.956      0.000       1.757       2.906\n",
       "$B$            1.6422      0.289      5.684      0.000       1.076       2.209\n",
       "$AB$           2.0262      0.211      9.609      0.000       1.613       2.440\n",
       "intercept     98.1921      0.112    873.772      0.000      97.972      98.412\n",
       "==============================================================================\n",
       "Omnibus:                     1708.714   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8378.454\n",
       "Skew:                          -0.745   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.229   Cond. No.                         43.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['intercept'] = 1.\n",
    "X['$A^2$'] = X['$A$'] ** 2\n",
    "X['$B^2$'] = X['$B$'] ** 2\n",
    "X['$AB$'] = X['$B$'] * X['$A$']\n",
    "\n",
    "model = WLS(X['$Y$'], X[['$D$', '$A^2$', '$B^2$', '$A$', '$B$', '$AB$', 'intercept']], weights=X['$W_{ATE}$'])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So we have a doubly robust regression by including $A$ and $B$ in the regression model, as well as the propensity score model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we use more general models with weighting and the g-formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the naive estimate first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 4501.6635\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 92us/step - loss: 104.1061\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 5.2603\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 5.2251\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 5.2519\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 5.2839\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 5.2317\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 5.2134\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 5.2928\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 5.2210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11320c0d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "x_variables = ['$D$']\n",
    "\n",
    "x_in = Input(shape=(len(x_variables),))\n",
    "h1 = Dense(100, activation='relu')(x_in)\n",
    "h2 = Dense(100, activation='relu')(h1)\n",
    "y_out = Dense(1, activation='linear')(h2)\n",
    "\n",
    "model = Model(inputs=[x_in], outputs=[y_out])\n",
    "model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "model.fit(X[x_variables], X['$Y$'], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['$D$'] = 1\n",
    "y1_hat = model.predict(df['$D$'])\n",
    "df['$D$'] = 0\n",
    "y0_hat = model.predict(df['$D$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8828003607486465"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1_hat - y0_hat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## close to the naive estimator! Now, let's try weighting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 155us/step - loss: 9988.2020\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 382.4181\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 7.5005\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 118us/step - loss: 7.4625\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 114us/step - loss: 7.4858\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 116us/step - loss: 7.4664\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 114us/step - loss: 7.4838\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 117us/step - loss: 7.4989\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 119us/step - loss: 7.4709\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 7.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116d29c90>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "x_variables = ['$D$']\n",
    "\n",
    "x_in = Input(shape=(len(x_variables),))\n",
    "h1 = Dense(100, activation='relu')(x_in)\n",
    "h2 = Dense(100, activation='relu')(h1)\n",
    "y_out = Dense(1, activation='linear')(h2)\n",
    "\n",
    "model = Model(inputs=[x_in], outputs=[y_out])\n",
    "model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "model.fit(X[x_variables], X['$Y$'], sample_weight=X['$W_{ATE}$'], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['$D$'] = 1\n",
    "y1_hat = model.predict(df['$D$'])\n",
    "df['$D$'] = 0\n",
    "y0_hat = model.predict(df['$D$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9776258569544325"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1_hat - y0_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much better! Now, let's try doubly-robust ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000000/1000000 [==============================] - 119s 119us/step - loss: 64.2769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11720dbd0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "x_variables = ['$D$', '$A$', '$B$']\n",
    "\n",
    "x_in = Input(shape=(len(x_variables),))\n",
    "h1 = Dense(100, activation='relu')(x_in)\n",
    "h2 = Dense(100, activation='relu')(h1)\n",
    "y_out = Dense(1, activation='linear')(h2)\n",
    "\n",
    "model = Model(inputs=[x_in], outputs=[y_out])\n",
    "model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "model.fit(X[x_variables], X['$Y$'], sample_weight=X['$W_{ATE}$'], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['$D$'] = 1\n",
    "y1_hat = model.predict(df[x_variables])\n",
    "df['$D$'] = 0\n",
    "y0_hat = model.predict(df[x_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.051592889997136"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1_hat - y0_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go crazy -- feedforward nets for everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 0.1721\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.1607\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.1603\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1602\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.1600\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.1600\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1598\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.1596\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.1600\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.1601\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "x_variables = ['$A$', '$B$']\n",
    "\n",
    "x_in = Input(shape=(len(x_variables),))\n",
    "h1 = Dense(100, activation='relu')(x_in)\n",
    "h2 = Dense(100, activation='relu')(h1)\n",
    "y_out = Dense(1, activation='linear')(h2)\n",
    "\n",
    "propensity_model = Model(inputs=[x_in], outputs=[y_out])\n",
    "propensity_model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "propensity_model.fit(X[x_variables], X['$D$'], epochs=10)\n",
    "\n",
    "X['$P(D=1|A,B)$'] = propensity_model.predict(X[['$A$', '$B$']])\n",
    "\n",
    "X['$W_{ATE}$'] = (X['$D$'] == 1)* 1. / X['$P(D=1|A,B)$'] + (X['$D$'] == 0)* 1. /(1. - X['$P(D=1|A,B)$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 179us/step - loss: 9558.9367\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 294.8762\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 150us/step - loss: 7.6703\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 114us/step - loss: 7.7014\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 116us/step - loss: 7.6981\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 7.6631\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 129us/step - loss: 7.6702\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 132us/step - loss: 7.6746\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 133us/step - loss: 7.6224\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 128us/step - loss: 7.6716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1154e1910>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "x_variables = ['$D$']\n",
    "\n",
    "x_in = Input(shape=(len(x_variables),))\n",
    "h1 = Dense(100, activation='relu')(x_in)\n",
    "h2 = Dense(100, activation='relu')(h1)\n",
    "y_out = Dense(1, activation='linear')(h2)\n",
    "\n",
    "model = Model(inputs=[x_in], outputs=[y_out])\n",
    "model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "model.fit(X[x_variables], X['$Y$'], sample_weight=X['$W_{ATE}$'], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['$D$'] = 1\n",
    "y1_hat = model.predict(df[x_variables])\n",
    "df['$D$'] = 0\n",
    "y0_hat = model.predict(df[x_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.458013286568061"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1_hat - y0_hat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.562727563487781"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1 - y0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
